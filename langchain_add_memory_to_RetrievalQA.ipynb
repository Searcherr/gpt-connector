{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:28:18.550445Z",
     "start_time": "2023-05-14T07:28:16.765897Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain import PromptTemplate\n",
    "from langchain.retrievers import TFIDFRetriever\n",
    "from openaikey import openai_api_key\n",
    "\n",
    "retriever = TFIDFRetriever.from_texts(\n",
    "    [\"Our client, a gentleman named Jason, has a dog whose name is Dobby\",\n",
    "     \"Jason has a good friend called Emma\",\n",
    "     \"Emma has a cat whose name is Sullivan\"])\n",
    "\n",
    "\n",
    "template = \"\"\"\n",
    "Use the following context (delimited by <ctx></ctx>) and the chat history (delimited by <hs></hs>) to answer the question:\n",
    "------\n",
    "<ctx>\n",
    "{context}\n",
    "</ctx>\n",
    "------\n",
    "<hs>\n",
    "{history}\n",
    "</hs>\n",
    "------\n",
    "{question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"context\", \"question\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(temperature=0, openai_api_key=openai_api_key),\n",
    "    chain_type='stuff',\n",
    "    retriever=retriever,\n",
    "    verbose=True,\n",
    "    chain_type_kwargs={\n",
    "        \"verbose\": True,\n",
    "        \"prompt\": prompt,\n",
    "        \"memory\": ConversationBufferMemory(\n",
    "            memory_key=\"history\",\n",
    "            input_key=\"question\"),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:28:33.510695Z",
     "start_time": "2023-05-14T07:28:32.207046Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new  chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new  chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new  chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Use the following context (delimited by <ctx></ctx>) and the chat history (delimited by <hs></hs>) to answer the question:\n",
      "------\n",
      "<ctx>\n",
      "Jason has a good friend called Emma\n",
      "\n",
      "Our client, a gentleman named Jason, has a dog whose name is Dobby\n",
      "\n",
      "Emma has a cat whose name is Sullivan\n",
      "</ctx>\n",
      "------\n",
      "<hs>\n",
      "\n",
      "</hs>\n",
      "------\n",
      "who's the client's friend?\n",
      "Answer:\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The client's friend is Emma.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run({\"query\": \"who's the client's friend?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:28:45.498358Z",
     "start_time": "2023-05-14T07:28:44.500865Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new  chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new  chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new  chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Use the following context (delimited by <ctx></ctx>) and the chat history (delimited by <hs></hs>) to answer the question:\n",
      "------\n",
      "<ctx>\n",
      "Emma has a cat whose name is Sullivan\n",
      "\n",
      "Our client, a gentleman named Jason, has a dog whose name is Dobby\n",
      "\n",
      "Jason has a good friend called Emma\n",
      "</ctx>\n",
      "------\n",
      "<hs>\n",
      "Human: who's the client's friend?\n",
      "AI: The client's friend is Emma.\n",
      "</hs>\n",
      "------\n",
      "and her pet's name is?\n",
      "Answer:\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Emma's pet's name is Sullivan.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run({\"query\": \"and her pet's name is?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-14T07:28:55.680483Z",
     "start_time": "2023-05-14T07:28:55.677115Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content=\"who's the client's friend?\", additional_kwargs={}, example=False), AIMessage(content=\"The client's friend is Emma.\", additional_kwargs={}, example=False), HumanMessage(content=\"and her pet's name is?\", additional_kwargs={}, example=False), AIMessage(content=\"Emma's pet's name is Sullivan.\", additional_kwargs={}, example=False)]), output_key=None, input_key='question', return_messages=False, human_prefix='Human', ai_prefix='AI', memory_key='history')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.combine_documents_chain.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new  chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new  chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new  chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Use the following context (delimited by <ctx></ctx>) and the chat history (delimited by <hs></hs>) to answer the question:\n",
      "------\n",
      "<ctx>\n",
      "Jason has a good friend called Emma\n",
      "\n",
      "Our client, a gentleman named Jason, has a dog whose name is Dobby\n",
      "\n",
      "Emma has a cat whose name is Sullivan\n",
      "</ctx>\n",
      "------\n",
      "<hs>\n",
      "Human: who's the client's friend?\n",
      "AI: The client's friend is Emma.\n",
      "Human: and her pet's name is?\n",
      "AI: Emma's pet's name is Sullivan.\n",
      "</hs>\n",
      "------\n",
      "Jason has a good friend called Milly. True or False?\n",
      "Answer:\n",
      "\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'False'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run({\"query\": \"Jason has a good friend called Milly. True or False?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-iSEZLgIeaROaNkescyAyZ3Xt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new  chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new  chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new  chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Use the following context (delimited by <ctx></ctx>) and the chat history (delimited by <hs></hs>) to answer the question:\n",
      "------\n",
      "<ctx>\n",
      "Emma has a cat whose name is Sullivan\n",
      "\n",
      "Jason has a good friend called Emma\n",
      "\n",
      "Our client, a gentleman named Jason, has a dog whose name is Dobby\n",
      "</ctx>\n",
      "------\n",
      "<hs>\n",
      "Human: who's the client's friend?\n",
      "AI: The client's friend is Emma.\n",
      "Human: and her pet's name is?\n",
      "AI: Emma's pet's name is Sullivan.\n",
      "Human: Jason has a good friend called Milly. True or False?\n",
      "AI: False\n",
      "</hs>\n",
      "------\n",
      "What did I just asked about?\n",
      "Answer:\n",
      "\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-iSEZLgIeaROaNkescyAyZ3Xt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-iSEZLgIeaROaNkescyAyZ3Xt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-iSEZLgIeaROaNkescyAyZ3Xt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 16.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-iSEZLgIeaROaNkescyAyZ3Xt on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues. Please add a payment method to your account to increase your rate limit. Visit https://platform.openai.com/account/billing to add a payment method..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You just asked about whether Jason has a good friend called Milly.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run({\"query\": \"What did I just asked about?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content=\"who's the client's friend?\", additional_kwargs={}, example=False), AIMessage(content=\"The client's friend is Emma.\", additional_kwargs={}, example=False), HumanMessage(content=\"and her pet's name is?\", additional_kwargs={}, example=False), AIMessage(content=\"Emma's pet's name is Sullivan.\", additional_kwargs={}, example=False), HumanMessage(content='Jason has a good friend called Milly. True or False?', additional_kwargs={}, example=False), AIMessage(content='False', additional_kwargs={}, example=False), HumanMessage(content='What did I just asked about?', additional_kwargs={}, example=False), AIMessage(content='You just asked about whether Jason has a good friend called Milly.', additional_kwargs={}, example=False)]), output_key=None, input_key='question', return_messages=False, human_prefix='Human', ai_prefix='AI', memory_key='history')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.combine_documents_chain.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
